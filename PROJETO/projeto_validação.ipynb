{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# carregar base de dados\n",
    "import os.path\n",
    "fileName = os.path.join('C:\\spark\\Data', 'teste_validacao.csv')\n",
    "numPartitions = 4\n",
    "rawData = sc.textFile(fileName, numPartitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Outlook = rawData.map(lambda x: x.split(\",\")[0])\n",
    "Temperature = rawData.map(lambda x: x.split(\",\")[1])\n",
    "Humidity = rawData.map(lambda x: x.split(\",\")[2])\n",
    "Windy = rawData.map(lambda x: x.split(\",\")[3])\n",
    "Play = rawData.map(lambda x: x.split(\",\")[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Entropia (classe):\n",
    "    \"\"\"Calcula a Entropia de Shannon de uma distribuição de dados.\n",
    "\n",
    "    Args:\n",
    "        classe (RDD): RDD contendo conjunto de dados a ser calculado a entropia.\n",
    "                      Valores devem ser categóricos.\n",
    "\n",
    "    Returns:\n",
    "        float: valor de Entropia de Shannon calculado para o RDD.\n",
    "    \"\"\"\n",
    "    #counts calcula paralelamente o conteúdo do RDD\n",
    "    #como tuplas contendo (tipo, quantidade)\n",
    "    counts = (classe.map(lambda x: (x, 1))\n",
    "                    .reduceByKey(lambda a,b: a + b))\n",
    "    # n recebe o valor total de itens do RDD\n",
    "    n = classe.count()\n",
    "    \n",
    "    # probs calcula a probabilidade de cada um dos estados do RDD\n",
    "    probs = counts.map(lambda x: x[1]/float(n))\n",
    "    \n",
    "    # Entropia calcula a entropia do RDD\n",
    "    ## a função map faz o calculo da Entropia de cada um dos estados\n",
    "    ## a função reduce faz o somatório da entropia de Shannon\n",
    "    entropia = (probs.map(lambda p: -p*math.log(p,2))\n",
    "                     .reduce(lambda a,b: a + b))\n",
    "    \n",
    "    # retorna valor escalar referênte a entropia do RDD.\n",
    "    return entropia\n",
    "\n",
    " \n",
    "def infoGain (feature, classe, H):\n",
    "    \"\"\"Calcula o ganho de informação de um atributo em relação a uma classe.\n",
    "\n",
    "    Args:\n",
    "        feature (RDD): RDD contendo os conjuntos de dados do atributo a ser\n",
    "                       calculado o Ganho de Informação\n",
    "        \n",
    "        classe (RDD): RDD contendo conjunto de dados da classe\n",
    "        \n",
    "        H (float): Entropia da Classe, previamente calculada.\n",
    "\n",
    "    Returns:\n",
    "        float: valor de ganho de informação (redução da Entropia) que o atributo fornece sobre a classe\n",
    "    \"\"\"\n",
    "    # calcula paralelamente o conteúdo do RDD\n",
    "    # como tuplas contendo (tipo, quantidade)\n",
    "    feat_count = feature.map(lambda x: (x, 1))\\\n",
    "                        .reduceByKey(lambda a,b: a + b)\\\n",
    "                        .collect()\n",
    "    # calcula as Entropias de um conjunto da classe dado cada um dos estados do atributo   \n",
    "    entropiasN = [Entropia(classe.zip(feature).filter(lambda x: x[1]==v).map(lambda x: x[0]))  for v,_ in feat_count]\n",
    "    \n",
    "    # calcula a quantidade de itens no atributo\n",
    "    n = classe.count()\n",
    "        \n",
    "    # calcula o ganho de informação do atributo.\n",
    "    ig = H - sum([(f[1]/float(n))*p for f,p in zip(feat_count, entropiasN)])\n",
    "    \n",
    "    return ig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940285958671\n"
     ]
    }
   ],
   "source": [
    "H =  Entropia (Play)\n",
    "print H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.246749819774\n"
     ]
    }
   ],
   "source": [
    "igOutlook = infoGain(Outlook, Play, H)\n",
    "print igOutlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029222565659\n"
     ]
    }
   ],
   "source": [
    "igTemperature = infoGain(Temperature, Play, H)\n",
    "print igTemperature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.151835501362\n"
     ]
    }
   ],
   "source": [
    "igHumidity = infoGain(Humidity, Play, H)\n",
    "print igHumidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0481270304083\n"
     ]
    }
   ],
   "source": [
    "igWindy = infoGain(Windy, Play, H)\n",
    "print igWindy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
