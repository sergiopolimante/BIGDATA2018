{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# carregar base de dados\n",
    "import os.path\n",
    "fileName = os.path.join('C:\\spark\\Data', 'DelayedFlights.csv')\n",
    "numPartitions = 1\n",
    "rawData = sc.textFile(fileName, numPartitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featMonth = rawData.map(lambda x: x.split(\",\")[2])\n",
    "featDayofMonth = rawData.map(lambda x: x.split(\",\")[3])\n",
    "featDayofWeek = rawData.map(lambda x: x.split(\",\")[4])\n",
    "featOrigin =  rawData.map(lambda x: x.split(\",\")[17])\n",
    "featDest =  rawData.map(lambda x: x.split(\",\")[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Entropia (classe):\n",
    "    \"\"\"Calcula a Entropia de Shannon de uma distribuição de dados.\n",
    "\n",
    "    Args:\n",
    "        classe (RDD): RDD contendo conjunto de dados a ser calculado a entropia.\n",
    "                      Valores devem ser categóricos.\n",
    "\n",
    "    Returns:\n",
    "        float: valor de Entropia de Shannon calculado para o RDD.\n",
    "    \"\"\"\n",
    "    #counts calcula paralelamente o conteúdo do RDD\n",
    "    #como tuplas contendo (tipo, quantidade)\n",
    "    counts = (classe.map(lambda x: (x, 1))\n",
    "                    .reduceByKey(lambda a,b: a + b))\n",
    "    # n recebe o valor total de itens do RDD\n",
    "    n = classe.count()\n",
    "    \n",
    "    # probs calcula a probabilidade de cada um dos estados do RDD\n",
    "    probs = counts.map(lambda x: x[1]/float(n))\n",
    "    \n",
    "    # Entropia calcula a entropia do RDD\n",
    "    ## a função map faz o calculo da Entropia de cada um dos estados\n",
    "    ## a função reduce faz o somatório da entropia de Shannon\n",
    "    entropia = (probs.map(lambda p: -p*math.log(p,2))\n",
    "                     .reduce(lambda a,b: a + b))\n",
    "    \n",
    "    # retorna valor escalar referênte a entropia do RDD.\n",
    "    return entropia\n",
    "\n",
    " \n",
    "def infoGain (feature, classe, H):\n",
    "    \"\"\"Calcula o ganho de informação de um atributo em relação a uma classe.\n",
    "\n",
    "    Args:\n",
    "        feature (RDD): RDD contendo os conjuntos de dados do atributo a ser\n",
    "                       calculado o Ganho de Informação\n",
    "        \n",
    "        classe (RDD): RDD contendo conjunto de dados da classe\n",
    "        \n",
    "        H (float): Entropia da Classe, previamente calculada.\n",
    "\n",
    "    Returns:\n",
    "        float: valor de ganho de informação (redução da Entropia) que o atributo fornece sobre a classe\n",
    "    \"\"\"\n",
    "    # calcula paralelamente o conteúdo do RDD\n",
    "    # como tuplas contendo (tipo, quantidade)\n",
    "    feat_count = feature.map(lambda x: (x, 1))\\\n",
    "                        .reduceByKey(lambda a,b: a + b)\\\n",
    "                        .collect()\n",
    "    # calcula as Entropias de um conjunto da classe dado cada um dos estados do atributo   \n",
    "    entropiasN = [Entropia(classe.zip(feature).filter(lambda x: x[1]==v).map(lambda x: x[0]))  for v,_ in feat_count]\n",
    "    \n",
    "    # calcula a quantidade de itens no atributo\n",
    "    n = classe.count()\n",
    "        \n",
    "    # calcula o ganho de informação do atributo.\n",
    "    ig = H - sum([(f[1]/float(n))*p for f,p in zip(feat_count, entropiasN)])\n",
    "    \n",
    "    return ig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n",
      "--- 31.870000124 seconds ---\n",
      "1.24766472434e-05\n",
      "--- 490.332000017 seconds ---\n",
      "numer of partition: 1\n"
     ]
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "numPartitions = 1\n",
    "rawData = sc.textFile(fileName, numPartitions)\n",
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featDayofWeek = rawData.map(lambda x: x.split(\",\")[4])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "H =  Entropia (Cancelled)\n",
    "print H\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "igDayofWeek = infoGain(featDayofWeek, Cancelled, H)\n",
    "print igDayofWeek\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print \"numer of partition:\", numPartitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n",
      "--- 32.8069999218 seconds ---\n",
      "1.24766472434e-05\n",
      "--- 495.953000069 seconds ---\n",
      "numer of partition: 2\n"
     ]
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "numPartitions = 2\n",
    "rawData = sc.textFile(fileName, numPartitions)\n",
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featDayofWeek = rawData.map(lambda x: x.split(\",\")[4])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "H =  Entropia (Cancelled)\n",
    "print H\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "igDayofWeek = infoGain(featDayofWeek, Cancelled, H)\n",
    "print igDayofWeek\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print \"numer of partition:\", numPartitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n",
      "--- 32.2950000763 seconds ---\n",
      "1.24766472434e-05\n",
      "--- 492.785000086 seconds ---\n",
      "numer of partition: 4\n"
     ]
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "numPartitions = 4\n",
    "rawData = sc.textFile(fileName, numPartitions)\n",
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featDayofWeek = rawData.map(lambda x: x.split(\",\")[4])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "H =  Entropia (Cancelled)\n",
    "print H\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "igDayofWeek = infoGain(featDayofWeek, Cancelled, H)\n",
    "print igDayofWeek\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print \"numer of partition:\", numPartitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n",
      "--- 32.1840000153 seconds ---\n",
      "1.24766472434e-05\n",
      "--- 489.861999989 seconds ---\n",
      "numer of partition: 6\n"
     ]
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "numPartitions = 6\n",
    "rawData = sc.textFile(fileName, numPartitions)\n",
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featDayofWeek = rawData.map(lambda x: x.split(\",\")[4])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "H =  Entropia (Cancelled)\n",
    "print H\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "igDayofWeek = infoGain(featDayofWeek, Cancelled, H)\n",
    "print igDayofWeek\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print \"numer of partition:\", numPartitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n",
      "--- 32.4440000057 seconds ---\n",
      "1.24766472434e-05\n",
      "--- 489.858999968 seconds ---\n",
      "numer of partition: 8\n"
     ]
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "numPartitions = 8\n",
    "rawData = sc.textFile(fileName, numPartitions)\n",
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featDayofWeek = rawData.map(lambda x: x.split(\",\")[4])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "H =  Entropia (Cancelled)\n",
    "print H\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "igDayofWeek = infoGain(featDayofWeek, Cancelled, H)\n",
    "print igDayofWeek\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print \"numer of partition:\", numPartitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n",
      "--- 37.8569998741 seconds ---\n",
      "1.24766472434e-05\n",
      "--- 594.200999975 seconds ---\n",
      "numer of partition: 16\n"
     ]
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "numPartitions = 16\n",
    "rawData = sc.textFile(fileName, numPartitions)\n",
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featDayofWeek = rawData.map(lambda x: x.split(\",\")[4])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "H =  Entropia (Cancelled)\n",
    "print H\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "igDayofWeek = infoGain(featDayofWeek, Cancelled, H)\n",
    "print igDayofWeek\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print \"numer of partition:\", numPartitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n",
      "--- 68.2899999619 seconds ---\n",
      "1.24766472434e-05\n",
      "--- 815.203999996 seconds ---\n",
      "numer of partition: 32\n"
     ]
    }
   ],
   "source": [
    "# carregar base de dados\n",
    "numPartitions = 32\n",
    "rawData = sc.textFile(fileName, numPartitions)\n",
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featDayofWeek = rawData.map(lambda x: x.split(\",\")[4])\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "H =  Entropia (Cancelled)\n",
    "print H\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "igDayofWeek = infoGain(featDayofWeek, Cancelled, H)\n",
    "print igDayofWeek\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print \"numer of partition:\", numPartitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
