{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# carregar base de dados\n",
    "import os.path\n",
    "fileName = os.path.join('C:\\spark\\Data', 'DelayedFlights.csv')\n",
    "numPartitions = 4\n",
    "rawData = sc.textFile(fileName, numPartitions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "featMonth = rawData.map(lambda x: x.split(\",\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# carregar base de dados\n",
    "import os.path\n",
    "fileName = os.path.join('C:\\spark\\Data', 'DelayedFlights.csv')\n",
    "\n",
    "numPartitions = 4\n",
    "rawData = sc.textFile(fileName, numPartitions)\n",
    "\n",
    "\n",
    "from collections import Counter    #é o modo certo de fazer utilizando counter?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def Entropia (classe):\n",
    "    #counts = Counter(classe.collect())  #(tipo: qnt, tipo: qn) #não paralelizado\n",
    "    \n",
    "    counts = (classe.map(lambda x: (x, 1))\n",
    "                   .reduceByKey(lambda a,b: a + b)\n",
    "             )\n",
    "    \n",
    "    n = classe.count()  \n",
    "    probs = counts.map(lambda x: x[1]/float(n))\n",
    "    #probs = map( ..., counts.items()) #[c/float(sum(counts)) for _,c in counts]  #não paralelizado\n",
    "    \n",
    "    #entropia = -sum([p*math.log(p,2) for p in probs] )  #não paralelizado\n",
    "    entropia = (probs.map(lambda p: -p*math.log(p,2))\n",
    "                     .reduce(lambda a,b: a + b))\n",
    "\n",
    "    return entropia\n",
    "\"\"\"\n",
    "\n",
    "def Entropia (classe):\n",
    "    \"\"\"Calcula a Entropia de Shannon de uma distribuição de dados.\n",
    "\n",
    "    Args:\n",
    "        classe (RDD): RDD contendo conjunto de dados a ser calculado a entropia.\n",
    "                      Valores devem ser categóricos.\n",
    "\n",
    "    Returns:\n",
    "        float: (float): valor de Entropia de Shannon calculado para o RDD.\n",
    "    \"\"\"\n",
    "    #counts calcula paralelamente o conteúdo do RDD\n",
    "    #como tuplas contendo (tipo, quantidade)\n",
    "    counts = (classe.map(lambda x: (x, 1))\n",
    "                    .reduceByKey(lambda a,b: a + b))\n",
    "    # n recebe o valor total de itens do RDD\n",
    "    n = classe.count()\n",
    "    \n",
    "    # probs calcula a probabilidade de cada um dos estados do RDD\n",
    "    probs = counts.map(lambda x: x[1]/float(n))\n",
    "    \n",
    "    # Entropia calcula a entropia do RDD\n",
    "    ## a função map faz o calculo da Entropia de cada um dos estados\n",
    "    ## a função reduce faz o somatório da entropia de Shannon\n",
    "    entropia = (probs.map(lambda p: -p*math.log(p,2))\n",
    "                     .reduce(lambda a,b: a + b))\n",
    "    \n",
    "    # retorna valor escalar referênte a entropia do RDD.\n",
    "    return entropia\n",
    "\n",
    " \n",
    "def infoGain (feature, classe, H):\n",
    "    #feat_count = Counter(feature.collect())  #(tipo: qnt, tipo: qn) #não paralelizado\n",
    "    feat_count = feature.map(lambda x: (x, 1))\\\n",
    "                        .reduceByKey(lambda a,b: a + b)\\\n",
    "                        .collect()\n",
    "    #print feat_count\n",
    "    \n",
    "    #feature1 = feature.take(100)\n",
    "    \n",
    "    #teste = [f==v for v,c in feat_count for f in feature1] \n",
    "    #print teste\n",
    "    \n",
    "    #probsCondic = [classe.filter(feature.map(lambda x: x ==v).collect()).map(Entropia) for v,_ in feat_count]\n",
    "    entropiasN = [Entropia(classe.zip(feature).filter(lambda x: x[1]==v).map(lambda x: x[0]))  for v,_ in feat_count]\n",
    "    \n",
    "    \n",
    "    #return feat_count, entropiasN\n",
    "    \n",
    "    #probsCondic = [classe.filter(feature==v).map(Entropia).collect() for v in feat_count]\n",
    "\n",
    "    #probsCondic = [classe.filter(feature==v).map(Entropia).collect() for v in feat_count]\n",
    "\n",
    "    #probsCondic = [classe.filter(feature==v).map(Entropia).collect() for v,c in feat_count]\n",
    "    \n",
    "\n",
    "    \n",
    "    #probs = probsCondic.map(Entropia)  #como filtrar classe através de um parametro no feature?\n",
    "    \n",
    "    \n",
    "    #print probs\n",
    "    #probs = [classe.filter(feature==v).map(Entropia) for v,c in feat_count.items()]  #como filtrar classe através de um parametro no feature?\n",
    "\n",
    "    #print probs\n",
    "    #n = sum([t[1] for t in feat_count])\n",
    "    n = classe.count()\n",
    "    #ig = H - sum([p/float(n)*p for p in entropiasN])\n",
    "    \n",
    "    \n",
    "    ig = H - sum([(f[1]/n)*p for f,p in zip(feat_count, entropiasN)])\n",
    "\n",
    "    \n",
    "    print ig\n",
    "    return ig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n"
     ]
    }
   ],
   "source": [
    "H =  Entropia (Cancelled)\n",
    "print H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featSample = sc.parallelize(featMonth.takeSample(False, 1000))\n",
    "classeSample = sc.parallelize(Cancelled.takeSample(False,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[619] at parallelize at PythonRDD.scala:175"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00425591582633\n",
      "0.00425591582633\n"
     ]
    }
   ],
   "source": [
    "ig = infoGain(featSample, classeSample, H)\n",
    "print ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'11', 68), (u'1', 91), (u'9', 48), (u'5', 77), (u'10', 50), (u'4', 81), (u'8', 71), (u'3', 99), (u'7', 98), (u'2', 108), (u'12', 115), (u'6', 94)] [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0]\n"
     ]
    }
   ],
   "source": [
    "print f, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dict(f).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-3ca1beb4a90b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "sum([p/float(sum(f))*p for p in h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = Cancelled.zip(featMonth).filter(lambda x: x[1]=='1').map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entropia(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({u'0': 183527})\n"
     ]
    }
   ],
   "source": [
    "print Counter(tmp.collect())  #(tipo: qnt, tipo: qn) #não paralelizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#counts = Counter(classe.collect())  #(tipo: qnt, tipo: qn)\n",
    "counts = Cancelled.map(lambda x: (x, 1))\\\n",
    "               .reduceByKey(lambda a,b: a + b)\n",
    "    \n",
    "print counts.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "counts = Counter(Cancelled.collect())  #(tipo: qnt, tipo: qn)\n",
    "print counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "contagem = Cancelled.map(lambda x: (x, 1))\\\n",
    "                    .reduceByKey(lambda a,b: a + b)\n",
    "print contagem.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cancelled = rawData.map(lambda x: x.split(\",\")[22])\n",
    "\n",
    "featMonth = rawData.map(lambda x: x.split(\",\")[2])\n",
    "\n",
    "#H =  Entropia (Cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print infoGain (featMonth, Cancelled, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teste = Counter(Cancelled.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print teste.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(teste.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[p*math.log(p) for _,p in test.item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'1', 633), (u'0', 1936125)]\n"
     ]
    }
   ],
   "source": [
    "    # calcula paralelamente o conteúdo do RDD\n",
    "    # como tuplas contendo (tipo, quantidade)\n",
    "feat_count = Cancelled.map(lambda x: (x, 1))\\\n",
    "                        .reduceByKey(lambda a,b: a + b)\\\n",
    "                        .collect()\n",
    "print feat_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
